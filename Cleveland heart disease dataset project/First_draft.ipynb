{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "dataset.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset.get('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 212)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values.reshape(1,y_train.values.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "y_train = y_train.values.reshape(1,y_train.values.shape[0])\n",
    "X_test = X_test.T\n",
    "y_test = y_test.values.reshape(1,y_test.values.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 212)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(0)\n",
    "    l = len(layer_dims)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = initialize_parameters([X_train.shape[0],100,60,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 13)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters['W1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(A_prev,W,b,activation):\n",
    "    Z = np.dot(W,A_prev)+b\n",
    "    if activation == \"sigmoid\":\n",
    "        A = 1/(1+np.exp(-Z))\n",
    "    if activation == \"tanh\":\n",
    "        A = np.tanh(Z)\n",
    "    if activation == \"relu\":\n",
    "        A = np.maximum(Z,0)\n",
    "    linear_cache = (A, W, b)\n",
    "    activation_cache = Z\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(X,parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = forward_propagation(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"relu\")\n",
    "        caches.append(cache)\n",
    "    AL, cache = forward_propagation(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    return AL,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))/m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ, A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, cache[1])\n",
    "        dA_prev, dW, db = linear_backward(dZ, cache[0])\n",
    "   \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, cache[1])\n",
    "        dA_prev, dW, db = linear_backward(dZ, cache[0])\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6917056958141469"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = compute_cost(AL,y_train.values.reshape(1,212))\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    dAL = -(np.divide(Y,AL)-np.divide(1-Y,1-AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL,current_cache,\"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)],current_cache,\"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)]-learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, layers_dims, learning_rate = 0.001, num_iterations = 3000, print_cost=False):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = model_forward(X,parameters)\n",
    "        print(AL.shape)\n",
    "        print(caches[2])\n",
    "        cost = compute_cost(AL,Y)\n",
    "        print(cost)\n",
    "        grads = model_backward(AL,Y,caches)\n",
    "        print(grads[dA2].shape)\n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\n",
    "        \n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 212)\n",
      "((array([[0.50078871, 0.5008497 , 0.50079979, 0.50134167, 0.50094723,\n",
      "        0.50089261, 0.50129754, 0.50105554, 0.50057082, 0.50104962,\n",
      "        0.50101633, 0.50109081, 0.50100225, 0.50108252, 0.50098919,\n",
      "        0.50134562, 0.50088102, 0.50095605, 0.50072194, 0.50100508,\n",
      "        0.50086139, 0.50089367, 0.50106948, 0.50085836, 0.50092351,\n",
      "        0.50110723, 0.50126181, 0.5006388 , 0.50090988, 0.50083372,\n",
      "        0.50102911, 0.50086632, 0.50086432, 0.50123066, 0.50093919,\n",
      "        0.50078725, 0.50084877, 0.5013991 , 0.50103721, 0.50108144,\n",
      "        0.50096674, 0.50095189, 0.50141456, 0.50148129, 0.50116266,\n",
      "        0.50127175, 0.50092241, 0.50078004, 0.50109846, 0.50091828,\n",
      "        0.50080414, 0.5012123 , 0.50075148, 0.50082218, 0.5009769 ,\n",
      "        0.50080614, 0.50093746, 0.50139232, 0.5008506 , 0.50089213,\n",
      "        0.50081078, 0.5008838 , 0.5006687 , 0.50121934, 0.50094449,\n",
      "        0.50075551, 0.50125883, 0.50105009, 0.50105226, 0.50119487,\n",
      "        0.50085616, 0.50118117, 0.50083621, 0.50099863, 0.50113687,\n",
      "        0.50096142, 0.50097353, 0.50078712, 0.50096823, 0.50118162,\n",
      "        0.5007608 , 0.50107504, 0.50131777, 0.50120621, 0.50114049,\n",
      "        0.50150592, 0.50088089, 0.50084279, 0.50103129, 0.50093574,\n",
      "        0.50119806, 0.50097445, 0.50107348, 0.50109703, 0.50079795,\n",
      "        0.50101699, 0.50115487, 0.50081168, 0.50117721, 0.50094699,\n",
      "        0.50129758, 0.50081685, 0.50119999, 0.50075299, 0.50084556,\n",
      "        0.50128091, 0.50069916, 0.50085304, 0.50089071, 0.50071941,\n",
      "        0.5007268 , 0.50083003, 0.5010824 , 0.50114364, 0.50101751,\n",
      "        0.50082135, 0.50093375, 0.50085449, 0.50232903, 0.5007744 ,\n",
      "        0.50128473, 0.50105014, 0.50096424, 0.50111296, 0.50091678,\n",
      "        0.50092191, 0.50088363, 0.50129323, 0.50099965, 0.50079172,\n",
      "        0.50114407, 0.50100481, 0.50064559, 0.50093566, 0.50118338,\n",
      "        0.50088144, 0.50103141, 0.50105371, 0.50103217, 0.50111439,\n",
      "        0.50122525, 0.50095883, 0.50077353, 0.50085378, 0.50093269,\n",
      "        0.50084855, 0.50130334, 0.50114376, 0.501115  , 0.5010175 ,\n",
      "        0.50091312, 0.50084835, 0.50108525, 0.50081603, 0.50102181,\n",
      "        0.50083708, 0.50099072, 0.50109905, 0.50069362, 0.50104723,\n",
      "        0.50082807, 0.50081   , 0.50123465, 0.50099541, 0.500825  ,\n",
      "        0.50093808, 0.50109553, 0.50083404, 0.50095602, 0.50085923,\n",
      "        0.50154978, 0.50090804, 0.50083859, 0.50062989, 0.50066415,\n",
      "        0.50095168, 0.50072912, 0.50089193, 0.50114865, 0.5011898 ,\n",
      "        0.5011761 , 0.50098655, 0.5009854 , 0.50126442, 0.50131775,\n",
      "        0.50098233, 0.50104145, 0.50085775, 0.50087056, 0.5008341 ,\n",
      "        0.50082358, 0.5012128 , 0.50096511, 0.50081213, 0.50078033,\n",
      "        0.50121827, 0.50134911, 0.50110724, 0.500846  , 0.5010646 ,\n",
      "        0.5007937 , 0.50087965, 0.50078411, 0.50107066, 0.50106611,\n",
      "        0.50091928, 0.50118922, 0.50101086, 0.50070695, 0.50078792,\n",
      "        0.50107609, 0.501176  ]]), array([[-9.39968138e-03,  1.93671328e-03, -1.30466525e-03,\n",
      "         1.63641079e-02, -1.24731689e-02,  4.55548011e-03,\n",
      "         7.87487320e-03,  1.05487879e-02,  1.40289529e-02,\n",
      "        -3.40315375e-03, -7.66242841e-03,  7.91060815e-03,\n",
      "        -5.68084152e-03, -1.68643778e-02,  1.79510666e-02,\n",
      "        -5.17075787e-03,  1.38535790e-02, -4.87560719e-03,\n",
      "         9.53825444e-03, -4.12738397e-03,  1.25456602e-02,\n",
      "         9.81135785e-03,  2.56520388e-02,  4.85501392e-03,\n",
      "        -1.63196277e-02, -1.98275764e-02,  7.19625075e-03,\n",
      "         3.30677368e-03, -3.87987145e-03,  1.61436781e-02,\n",
      "        -1.76289054e-02, -2.99236816e-03, -2.81605326e-03,\n",
      "        -4.91333563e-03,  1.06210993e-03,  6.11043994e-03,\n",
      "         4.48229062e-03,  8.11050707e-03, -5.04925308e-04,\n",
      "        -1.03178552e-02,  5.82334958e-03,  8.44498557e-03,\n",
      "        -3.84941375e-03, -1.35508294e-02,  6.30687517e-03,\n",
      "         3.17111212e-03,  9.54002201e-05,  8.56830298e-03,\n",
      "         1.80198577e-02, -9.95239426e-03,  3.21184747e-02,\n",
      "        -1.66101250e-03,  1.77663650e-02, -3.34089312e-03,\n",
      "        -2.28533556e-03, -8.10918497e-04, -1.72715697e-02,\n",
      "         4.43460018e-03, -7.04759253e-03,  5.32491845e-03]]), array([[0.]])), array([[0.00315486, 0.00339879, 0.00319917, 0.0053667 , 0.00378894,\n",
      "        0.00357043, 0.00519017, 0.00422218, 0.0022833 , 0.0041985 ,\n",
      "        0.00406533, 0.00436324, 0.004009  , 0.0043301 , 0.00395676,\n",
      "        0.00538248, 0.00352408, 0.0038242 , 0.00288775, 0.00402034,\n",
      "        0.00344555, 0.00357468, 0.00427793, 0.00343346, 0.00369405,\n",
      "        0.00442893, 0.00504726, 0.00255519, 0.00363951, 0.00333488,\n",
      "        0.00411646, 0.00346527, 0.00345729, 0.00492263, 0.00375676,\n",
      "        0.003149  , 0.00339507, 0.00559642, 0.00414887, 0.00432578,\n",
      "        0.00386698, 0.00380757, 0.00565824, 0.00592516, 0.00465065,\n",
      "        0.00508703, 0.00368963, 0.00312017, 0.00439387, 0.00367314,\n",
      "        0.00321657, 0.00484923, 0.0030059 , 0.00328871, 0.0039076 ,\n",
      "        0.00322457, 0.00374984, 0.00556928, 0.00340242, 0.00356851,\n",
      "        0.00324313, 0.0035352 , 0.0026748 , 0.00487738, 0.00377795,\n",
      "        0.00302206, 0.00503533, 0.00420037, 0.00420905, 0.0047795 ,\n",
      "        0.00342464, 0.00472467, 0.00334484, 0.00399454, 0.0045475 ,\n",
      "        0.00384567, 0.00389414, 0.00314848, 0.00387294, 0.00472649,\n",
      "        0.0030432 , 0.00430018, 0.0052711 , 0.00482484, 0.00456196,\n",
      "        0.00602372, 0.00352356, 0.00337118, 0.00412516, 0.00374297,\n",
      "        0.00479223, 0.00389779, 0.00429394, 0.00438815, 0.00319182,\n",
      "        0.00406797, 0.00461947, 0.00324673, 0.00470883, 0.00378797,\n",
      "        0.00519033, 0.00326741, 0.00479997, 0.00301195, 0.00338224,\n",
      "        0.00512367, 0.00279664, 0.00341218, 0.00356284, 0.00287762,\n",
      "        0.0029072 , 0.00332012, 0.0043296 , 0.00457455, 0.00407003,\n",
      "        0.00328538, 0.00373502, 0.00341796, 0.00931618, 0.00309762,\n",
      "        0.00513893, 0.00420057, 0.00385697, 0.00445185, 0.00366712,\n",
      "        0.00368766, 0.00353451, 0.00517293, 0.00399861, 0.00316687,\n",
      "        0.00457629, 0.00401923, 0.00258234, 0.00374263, 0.00473352,\n",
      "        0.00352577, 0.00412564, 0.00421483, 0.00412868, 0.00445755,\n",
      "        0.00490099, 0.00383533, 0.00309411, 0.00341514, 0.00373075,\n",
      "        0.00339422, 0.00521336, 0.00457504, 0.00446   , 0.00407   ,\n",
      "        0.00365249, 0.0033934 , 0.00434101, 0.00326412, 0.00408726,\n",
      "        0.00334834, 0.00396289, 0.0043962 , 0.00277449, 0.00418892,\n",
      "        0.00331229, 0.00324002, 0.00493859, 0.00398164, 0.00330001,\n",
      "        0.00375232, 0.00438213, 0.00333618, 0.00382408, 0.00343694,\n",
      "        0.00619913, 0.00363217, 0.00335438, 0.00251955, 0.0026566 ,\n",
      "        0.00380673, 0.00291648, 0.00356774, 0.00459459, 0.0047592 ,\n",
      "        0.0047044 , 0.00394619, 0.00394159, 0.00505769, 0.00527102,\n",
      "        0.00392931, 0.00416583, 0.003431  , 0.00348225, 0.00333642,\n",
      "        0.00329431, 0.00485122, 0.00386045, 0.00324853, 0.00312131,\n",
      "        0.00487309, 0.00539644, 0.00442898, 0.003384  , 0.00425841,\n",
      "        0.00317481, 0.0035186 , 0.00313643, 0.00428266, 0.00426444,\n",
      "        0.00367712, 0.00475687, 0.00404343, 0.00282781, 0.00315169,\n",
      "        0.00430436, 0.00470402]]))\n",
      "0.6929039460624572\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dA2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-310-1f96d67ca403>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayers_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-308-0580d6c9f1af>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdA2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dA2' is not defined"
     ]
    }
   ],
   "source": [
    "parameters = optimize(X_train, y_train,layers_dims = [X_train.shape[0],100,60,1], num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
